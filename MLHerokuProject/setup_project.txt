# INSTALL GIT
git --version


# INSTALL PIP
curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
python get-pip.py


# CREATE THE PROJECT DIRECTORY
mkdir sentiment_analysis
cd sentiment_analysis

# INSTALL VIRTUALENV
pip install virtualenv

# CREATE A VIRLTUAL ENVIRONMENT INSIDE THE PROJECT
virtualenv -p python3 herokuenv


# ACTIVATE VIRTUAL ENV
source herokuenv/bin/activate

# INSTALL DJANGO 3
pip install django

# START A DJANGO PROJECT 
django-admin startproject sentiment_analysis .

# TEST THE INSTALLATION BY STARTING THE DJANGO TEST SERVER
python manage.py runserver

python manage.py migrate

======================

django-admin startapp modelling

cd modelling
wget -c http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz
tar xvfz review_polarity.tar.gz



==================================
pip install scikit-learn



##################################################
## Python ML code
##################################################

modelling$ python
Python 3.6.9 (default, Apr 18 2020, 01:56:04) 
[GCC 8.4.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import sys
>>> from sklearn.feature_extraction.text import TfidfVectorizer
>>> from sklearn.svm import LinearSVC
>>> from sklearn.pipeline import Pipeline
>>> from sklearn.model_selection import GridSearchCV
>>> from sklearn.datasets import load_files
>>> from sklearn.model_selection import train_test_split
>>> from sklearn import metrics
>>> 

>>> movie_reviews_data_folder = "txt_sentoken"
>>> dataset = load_files(movie_reviews_data_folder, shuffle=False)
>>> print("nSamples: %d" % len(dataset.data))
nSamples: 2000
>>> docs_train, docs_test, y_train, y_test = train_test_split(
...     dataset.data, dataset.target, test_size=0.25, random_state=None)
>>> pipeline = Pipeline([('vect',TfidfVectorizer(min_df=3,max_df=0.95)) , ('clf', LinearSVC(C=1)),])
>>> parameters ={'vect__ngram_range':[(1,1),(1,2),(1,3)],}
>>> grid_search = GridSearchCV(pipeline, parameters, n_jobs=1)
>>> grid_search.fit(docs_train, y_train)
GridSearchCV(cv=None, error_score=nan,
             estimator=Pipeline(memory=None,
                                steps=[('vect',
                                        TfidfVectorizer(analyzer='word',
                                                        binary=False,
                                                        decode_error='strict',
                                                        dtype=<class 'numpy.float64'>,
                                                        encoding='utf-8',
                                                        input='content',
                                                        lowercase=True,
                                                        max_df=0.95,
                                                        max_features=None,
                                                        min_df=3,
                                                        ngram_range=(1, 1),
                                                        norm='l2',
                                                        preprocessor=None,
                                                        smooth_idf=True,
                                                        stop_words=None,
                                                        strip_...
                                        LinearSVC(C=1, class_weight=None,
                                                  dual=True, fit_intercept=True,
                                                  intercept_scaling=1,
                                                  loss='squared_hinge',
                                                  max_iter=1000,
                                                  multi_class='ovr',
                                                  penalty='l2',
                                                  random_state=None, tol=0.0001,
                                                  verbose=0))],
                                verbose=False),
             iid='deprecated', n_jobs=1,
             param_grid={'vect__ngram_range': [(1, 1), (1, 2), (1, 3)]},
             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,
             scoring=None, verbose=0)
>>> 
>>> print("Best score: %0.3f" % grid_search.best_score_)
Best score: 0.862
>>>
>>> best_parameters = grid_search.best_estimator_.get_params()
>>> for param_name in sorted(parameters.keys()):
...    print("\t%s: %r" % (param_name, best_parameters[param_name]))
... 
	vect__ngram_range: (1, 2)
>>> best_model = grid_search.best_estimator_
>>> from sklearn.externals import joblib
/home/shree/Documents/javascript-project/PythonProjects/myPythonProgs/MLHerokuProject/sentiment_analysis/herokuenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
>>> 
>>> joblib.dump(grid_search.best_estimator_, 'model.file', compress=1)
['model.file']
>>> 
>>> from sklearn.metrics import confusion_matrix
>>> y_hat_test = best_model.predict(docs_test)
>>> print(len(docs_test))
 
>>> confusion_matrix(y_test, y_hat_test)
array([[222,  47],
       [ 30, 201]])
>>> y_hat_test = best_model.predict(docs_test)
>>> from sklearn.metrics import confusion_matrix
>>> (222+201)/len(y_test)
0.846
>>> 


##################################################
## END: Python Code
##################################################
